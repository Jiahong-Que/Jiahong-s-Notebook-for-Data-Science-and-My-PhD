å½“ç„¶å¯ä»¥ï¼Œä¸‹é¢æ˜¯ä¸€ä»½ç³»ç»Ÿè€Œè¯¦ç»†çš„ HDF5 æ–‡ä»¶å­¦ä¹ æŒ‡å—ï¼Œæ¶µç›–ä»æ¦‚å¿µåˆ°å®é™…è¯»å–å’Œåˆ†æçš„å…¨è¿‡ç¨‹ï¼Œé€‚åˆä½ åœ¨æ•°æ®ç§‘å­¦æˆ–AIå·¥ç¨‹é¡¹ç›®ä¸­æ·±å…¥ä½¿ç”¨ã€‚æˆ‘ä»¬ä»¥ Python ä¸­å¸¸ç”¨çš„ `h5py` åº“ä¸ºä¾‹è¿›è¡Œè®²è§£ã€‚

---

## ğŸ§© ä¸€ã€HDF5 æ˜¯ä»€ä¹ˆï¼Ÿ

**HDF5ï¼ˆHierarchical Data Format version 5ï¼‰** æ˜¯ä¸€ç§ä¸“ä¸ºå¤§è§„æ¨¡æ•°æ®å­˜å‚¨è€Œè®¾è®¡çš„æ–‡ä»¶æ ¼å¼å’Œæ•°æ®æ¨¡å‹ï¼Œé€‚ç”¨äºç§‘å­¦è®¡ç®—ã€æœºå™¨å­¦ä¹ ã€é¥æ„Ÿç­‰åœºæ™¯ã€‚

### âœ… ç‰¹ç‚¹

* **å±‚çº§ç»“æ„ï¼ˆç±»æ¯”æ–‡ä»¶å¤¹ï¼‰**ï¼šæ–‡ä»¶å†…å¯ä»¥åµŒå¥—å¤šä¸ªç»„ï¼ˆGroupï¼‰ï¼Œæ¯ä¸ªç»„ä¸‹é¢å¯åŒ…å«æ•°æ®é›†ï¼ˆDatasetï¼‰å’Œå­ç»„ã€‚
* **é«˜æ€§èƒ½**ï¼šæ”¯æŒå‹ç¼©ã€åˆ†å—ã€å¹¶è¡ŒI/Oç­‰ã€‚
* **å¼ºå¤§çš„å…ƒæ•°æ®æ”¯æŒ**ï¼šå¯ä»¥ä¸ºç»„å’Œæ•°æ®é›†æ·»åŠ å±æ€§ï¼ˆattributeï¼‰ã€‚
* **è·¨å¹³å°ã€è·¨è¯­è¨€**ï¼šæ”¯æŒ Pythonï¼ˆh5pyã€PyTablesï¼‰ã€MATLABã€C/C++ ç­‰ã€‚

---

## ğŸ“ äºŒã€HDF5 çš„ç»“æ„

```
my_file.hdf5
â”‚
â”œâ”€â”€ /Group1
â”‚   â”œâ”€â”€ /Subgroup1
â”‚   â”‚   â”œâ”€â”€ Dataset1  (ä¸€ä¸ªæ•°ç»„)
â”‚   â”‚   â””â”€â”€ Dataset2  (å¦ä¸€ä¸ªæ•°ç»„)
â”‚   â””â”€â”€ Attributes
â”‚
â”œâ”€â”€ /Group2
â”‚   â””â”€â”€ Dataset3
â”‚
â””â”€â”€ Attributes (ä¾‹å¦‚ï¼šsource="Sensor", date="2025-05-21")
```

---

## ğŸ§ª ä¸‰ã€å¦‚ä½•è¯»å– HDF5 æ–‡ä»¶ï¼ˆä½¿ç”¨ h5pyï¼‰

```bash
pip install h5py
```

### 1. åŸºç¡€è¯»å–æ“ä½œ

```python
import h5py

# æ‰“å¼€æ–‡ä»¶ï¼ˆåªè¯»æ¨¡å¼ï¼‰
with h5py.File("your_file.hdf5", "r") as f:
    print("ğŸ—‚ï¸ é¡¶å±‚ keys:", list(f.keys()))  # åˆ—å‡ºé¡¶å±‚ç»„å
    group = f['Group1']
    print("ğŸ“Œ å­ç»„ keys:", list(group.keys()))
    
    # è¯»å–ä¸€ä¸ªæ•°æ®é›†
    data = group['Subgroup1']['Dataset1'][:]  # [:] è¡¨ç¤ºå°†å…¶è½¬æ¢ä¸º NumPy æ•°ç»„
    print("ğŸ“ æ•°æ® shape:", data.shape)
```

### 2. æŸ¥çœ‹å…ƒä¿¡æ¯ï¼ˆå±æ€§ï¼‰

```python
# æ‰“å°å±æ€§
for key, value in group.attrs.items():
    print(f"{key}: {value}")
```

---

## ğŸ§  å››ã€å¦‚ä½•åˆ†æ HDF5 ä¸­çš„æ•°æ®

è¯»å–åï¼Œæ•°æ®ä¸€èˆ¬æ˜¯å¤šç»´æ•°ç»„ï¼ˆNumPyï¼‰ã€‚ä½ å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼è¿›è¡Œåˆ†æï¼š

### 1. åŸºç¡€ç»Ÿè®¡åˆ†æ

```python
import numpy as np

print("å¹³å‡å€¼:", np.mean(data, axis=0))
print("æ ‡å‡†å·®:", np.std(data, axis=0))
print("æœ€å¤§å€¼:", np.max(data))
print("æœ€å°å€¼:", np.min(data))
```

### 2. å¯è§†åŒ–åˆ†æï¼ˆå¦‚åŠ é€Ÿåº¦ã€æ¸©åº¦ç­‰ä¼ æ„Ÿå™¨æ•°æ®ï¼‰

```python
import matplotlib.pyplot as plt

plt.plot(data[:100, 0], label="x-axis")
plt.plot(data[:100, 1], label="y-axis")
plt.plot(data[:100, 2], label="z-axis")
plt.title("Acceleration over time")
plt.xlabel("Time step")
plt.ylabel("Acceleration")
plt.legend()
plt.show()
```

### 3. å¿«é€Ÿé¢‘åŸŸåˆ†æï¼ˆä¾‹å¦‚ç”¨ FFT çœ‹ä¿¡å·é¢‘ç‡ï¼‰

```python
from scipy.fft import fft

fft_vals = fft(data[:, 0])
plt.plot(np.abs(fft_vals))
plt.title("Frequency domain (X axis)")
plt.xlabel("Frequency bin")
plt.ylabel("Amplitude")
plt.show()
```

---

## ğŸ§° äº”ã€HDF5 ä¸ç‰¹å¾å·¥ç¨‹ï¼ˆFeature Engineeringï¼‰çš„ç»“åˆ

å¦‚æœä½ æ˜¯åœ¨åšæ™ºèƒ½ä¼ æ„Ÿå™¨æ•°æ®åˆ†æï¼ˆæ¯”å¦‚ Smart Pouch é¡¹ç›®ï¼‰ï¼Œä½ å¯ä»¥ï¼š

### 1. åŸºäºæ—¶é—´çª—æå–ç‰¹å¾

```python
window_size = 1000  # æ¯1000ä¸ªç‚¹æå–ä¸€æ¬¡
features = []

for i in range(0, len(data) - window_size, window_size):
    window = data[i:i+window_size, :]
    feature_vec = [
        np.mean(window[:, 0]), np.std(window[:, 0]),  # xè½´åŠ é€Ÿåº¦å‡å€¼/æ–¹å·®
        np.mean(window[:, 1]), np.std(window[:, 1]),  # yè½´
        np.mean(window[:, 2]), np.std(window[:, 2]),  # zè½´
    ]
    features.append(feature_vec)

features = np.array(features)
print("ç‰¹å¾ shape:", features.shape)
```

### 2. ä¿å­˜å¤„ç†åçš„ç‰¹å¾ä¸ºæ–°çš„ HDF5 æ–‡ä»¶

```python
with h5py.File("processed_features.hdf5", "w") as f:
    f.create_dataset("features", data=features)
```

---

## ğŸ— å…­ã€å¦‚ä½•åˆ›å»ºå’Œå†™å…¥ HDF5 æ–‡ä»¶

```python
with h5py.File("example_output.hdf5", "w") as f:
    dset = f.create_dataset("data", data=np.random.rand(100, 3))
    dset.attrs['description'] = "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„ä¸‰è½´åŠ é€Ÿåº¦æ•°æ®"
    f.attrs['created_by'] = "Jiahong"
```

---

## ğŸ›  ä¸ƒã€å¸¸ç”¨è¿›é˜¶æ“ä½œ

### 1. éå†æ•´ä¸ª HDF5 æ–‡ä»¶ç»“æ„

```python
def explore(h5obj, indent=0):
    for key in h5obj.keys():
        item = h5obj[key]
        print("  " * indent + f"ğŸ“ {key}: {'Group' if isinstance(item, h5py.Group) else 'Dataset'}")
        if isinstance(item, h5py.Group):
            explore(item, indent + 1)

with h5py.File("your_file.hdf5", "r") as f:
    explore(f)
```

### 2. åˆ†æ®µè¯»å–å¤§æ•°æ®ï¼ˆä¸ä¸€æ¬¡æ€§å…¨éƒ¨åŠ è½½ï¼‰

```python
with h5py.File("large_file.hdf5", "r") as f:
    dset = f["sensor_data"]
    chunk = dset[0:10000]  # åªè¯»å–å‰1ä¸‡ä¸ªæ•°æ®
```

---

## ğŸ§¾ å…«ã€å…¸å‹åœºæ™¯ä¸å»ºè®®

| åœºæ™¯              | å»ºè®®                             |
| --------------- | ------------------------------ |
| å¤šç»„å®éªŒæ•°æ®ï¼Œæ¯ç»„æ•°æ®ç»“æ„ç±»ä¼¼ | ä½¿ç”¨å¤šä¸ª Groupï¼Œç»“æ„æ¸…æ™°                |
| æ¯ä¸ªæ•°æ®é›†æœ‰è¯´æ˜ä¿¡æ¯      | ä½¿ç”¨ `attrs` å­˜å‚¨å…ƒæ•°æ®               |
| æ•°æ®è¾ƒå¤§ï¼Œéœ€ä¼˜åŒ–è¯»å–é€Ÿåº¦    | è®¾ç½®åˆé€‚çš„ `chunks` å’Œ `compression` |
| ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶          | ä¿å­˜ä¸åŒç‰ˆæœ¬ä¸ºä¸åŒ Group åç§°             |

---

## âœ… ä¹ã€å¸¸è§é—®é¢˜

| é—®é¢˜                             | åŸå›            | è§£å†³åŠæ³•                     |
| ------------------------------ | ------------ | ------------------------ |
| `KeyError`                     | æŒ‡å®šçš„ç»„åæˆ–æ•°æ®é›†ä¸å­˜åœ¨ | ä½¿ç”¨ `list(f.keys())` æŸ¥çœ‹é”®å |
| æ–‡ä»¶è¿‡å¤§è¯»å–æ…¢                        | æ²¡æœ‰ä½¿ç”¨åˆ†æ®µæˆ–å‹ç¼©    | ç»“åˆåˆ†å—è¯»å–å’Œ `gzip` å‹ç¼©        |
| `OSError: Unable to open file` | æ–‡ä»¶æŸåæˆ–è·¯å¾„é”™è¯¯    | æ£€æŸ¥è·¯å¾„ï¼Œç¡®è®¤æ–‡ä»¶æœªæŸå             |

---

## ğŸ“š åã€æ¨èå­¦ä¹ èµ„æº

* å®˜æ–¹æ–‡æ¡£ï¼š[https://www.h5py.org](https://www.h5py.org)
* HDF Group å®˜ç½‘ï¼š[https://www.hdfgroup.org](https://www.hdfgroup.org)
* æ•™ç¨‹é¡¹ç›®ï¼š[https://github.com/h5py/h5py](https://github.com/h5py/h5py)

---

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥ï¼š

* å¸®ä½ **åˆ†æä½ çš„ HDF5 æ–‡ä»¶ç»“æ„**
* æå–ç‰¹å®šçš„æ•°æ®å¹¶ä¿å­˜ä¸º CSVã€Parquet
* è®¾è®¡ä¸€ä¸ªå®Œæ•´çš„æ•°æ®åˆ†æ pipelineï¼ˆç»“åˆ Git + DVC + MLflowï¼‰

éœ€è¦æˆ‘ç»§ç»­çš„è¯ï¼Œåªè¦æŠŠä½ çš„ HDF5 æ–‡ä»¶ç»“æ„æˆªå›¾æˆ–å‘ç»™æˆ‘éƒ¨åˆ†å†…å®¹å³å¯ ğŸ™Œ
